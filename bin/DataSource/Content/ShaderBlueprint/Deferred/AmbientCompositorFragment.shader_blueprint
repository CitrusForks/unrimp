/*********************************************************\
 * Copyright (c) 2012-2017 The Unrimp Team
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy of this software
 * and associated documentation files (the "Software"), to deal in the Software without
 * restriction, including without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in all copies or
 * substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING
 * BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
 * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
\*********************************************************/


//[-------------------------------------------------------]
//[ Includes                                              ]
//[-------------------------------------------------------]
@includepiece(15)	// "Core.shader_piece"
@includepiece(16)	// "TangentFrame.shader_piece"
@includepiece(164)	// "PhysicallyBasedShading.shader_piece"


//[-------------------------------------------------------]
//[ Definitions                                           ]
//[-------------------------------------------------------]
@insertpiece(SetCrossPlatformSettings)


//[-------------------------------------------------------]
//[ Input / output                                        ]
//[-------------------------------------------------------]
// Attribute input / output
INPUT_BEGIN
	INPUT_TEXTURE_COORDINATE(float2, TexCoordVS, 0)	// Texture coordinate
	INPUT_TEXTURE_COORDINATE(float3, ViewRayVS,  1)	// View space ray used for view space position reconstruction
	INPUT_VERTEX_DRAW_ID							// Draw ID
INPUT_END
OUTPUT_BEGIN
	OUTPUT_COLOR(0)
OUTPUT_END

// Uniform buffers
struct PassDataStruct
{
	float4   ViewSpaceFrustumCorners[4];
	float4x4 ClipSpaceToViewSpaceMatrix;
	float4x4 ViewSpaceToWorldSpaceMatrix;
	float4x4 ShadowMatrix;
	float3   ViewSpaceSunLightDirection;
	float    Wetness;
	float3   AmbientColor;
	float4	 ViewSpaceToWorldSpaceQuaternion;
	float3   SunLightColor;
	float3	 CameraWorldSpacePosition;
	float3	 LightClustersScale;
	float3	 LightClustersBias;
	float2   ViewportSize;
	float2 	 ProjectionParameters;
};
UNIFORM_BUFFER_BEGIN(PassUniformBuffer, 0)
	PassDataStruct PassData;
UNIFORM_BUFFER_END

// Texture buffers
TEXTURE_BUFFER(float4, LightTextureBuffer, 0)	// "LIGHT"

// Samplers
SAMPLER_STATE(SamplerPoint, 0)
SAMPLER_STATE(SamplerLinear, 1)

// Textures
@property(NumberOfMultisamples)
	TEXTURE_2D_MS(GBufferMap0, @value(NumberOfMultisamples), 1)	// GBuffer 0: rgb = diffuse color, a = alpha unused (required for blend operations)
	TEXTURE_2D_MS(GBufferMap1, @value(NumberOfMultisamples), 2)	// GBuffer 1: rgb = view space normal, a = roughness
	TEXTURE_2D_MS(GBufferMap2, @value(NumberOfMultisamples), 3)	// GBuffer 2: rgb = emissive color, a = metallic
	TEXTURE_2D_MS(DepthMap, @value(NumberOfMultisamples), 4)
@end
@property(!NumberOfMultisamples)
	TEXTURE_2D(GBufferMap0, 1)	// GBuffer 0: rgb = diffuse color, a = alpha unused (required for blend operations)
	TEXTURE_2D(GBufferMap1, 2)	// GBuffer 1: rgb = view space normal, a = roughness
	TEXTURE_2D(GBufferMap2, 3)	// GBuffer 2: rgb = emissive color, a = metallic
	TEXTURE_2D(DepthMap, 4)
@end
TEXTURE_2D(ShadowMap, 5)
TEXTURE_2D(ScreenSpaceAmbientOcclusionMap, 6)
TEXTURE_CUBE(ReflectionCubeMap, 7)
TEXTURE_3D_UINT(LightClustersMap3D, 8)


//[-------------------------------------------------------]
//[ Functions                                             ]
//[-------------------------------------------------------]
@insertpiece(DefineGetTangentFrame)
@insertpiece(DefinePhysicallyBasedShading)


//[-------------------------------------------------------]
//[ Pieces                                                ]
//[-------------------------------------------------------]
// TODO(co) Make this to a shader piece
float GetLinearDepth(float depth)
{
	return PassData.ProjectionParameters.y / (depth - PassData.ProjectionParameters.x);
}

float3 CalculateColorByGBuffer(float3 viewRay, float2 screenSpacePosition, float4 gbuffer0Value, float4 gbuffer1Value, float4 gbuffer2Value, float depth, float screenSpaceAmbientOcclusion)
{
	// Gather GBuffer data
	float3 diffuse		   = gbuffer0Value.rgb;
	float3 viewSpaceNormal = gbuffer1Value.rgb;
	float  roughness	   = gbuffer1Value.a;
	float3 emissive		   = gbuffer2Value.rgb;
	float  metallic		   = SATURATE(PassData.Wetness + gbuffer2Value.a);

	// Scale the view ray by the ratio of the linear z value to the projected view ray
	// -> For details see "The Danger Zone" - "Position From Depth 3: Back In The Habit" - "Written by MJPSeptember 5, 2010" - https://mynameismjp.wordpress.com/2010/09/05/position-from-depth-3/
	float3 viewSpacePosition = viewRay * (GetLinearDepth(depth) / dot(float3(0.0f, 0.0f, 1.0f), viewRay));

	// Derive data
	float3 viewSpaceIncident = -normalize(viewSpacePosition);	// In view space, the camera is at the origin
	float3 worldSpacePosition = MATRIX_MUL(PassData.ViewSpaceToWorldSpaceMatrix, float4(viewSpacePosition.xyz, 1.0f)).xyz;
	float3 worldSpaceNormal = MultiplyQuaternionVector(PassData.ViewSpaceToWorldSpaceQuaternion, viewSpaceNormal);

	// TODO(co) Shadow: Totally primitive to have something to start with
	float shadowVisibility = 1.0f;
	{
		float4 shadowTextureCoordinate = MATRIX_MUL(PassData.ShadowMatrix, float4(worldSpacePosition, 1.0f));
		if (SAMPLE_2D_LOD(ShadowMap, SamplerPoint, float4(shadowTextureCoordinate.xy, 0.0f, 0.0f)).r < shadowTextureCoordinate.z - 0.001f)
		{
			shadowVisibility = 0.0f;
		}
	}

	// Ambient term
	float3 color = diffuse * (PassData.AmbientColor.rgb + CalculateHemisphereLighting(worldSpaceNormal.xyz, PassData.AmbientColor.rgb * 0.7f, PassData.AmbientColor.rgb * 0.2f));

	// Directional sun light, our primary light
	if (shadowVisibility > 0.0f)
	{
		color += CalculateLighting(diffuse, roughness, metallic, viewSpaceNormal, viewSpaceIncident, PassData.ViewSpaceSunLightDirection, PassData.SunLightColor);
	}

	// Compute light cluster and fetch its light mask: Basing on the clustered shading demo from Emil Persson - http://humus.name/index.php?page=3D
	// "
	// We're using a 32bit integer format where each set bit enables the light of that index.
	// This supports up to 32 lights, which is enough for this demo, and probably for some games. It's possible to expand if more lights are needed,
	// for instance RGBA32_UINT for up to 128 lights in a single fetch, which is enough for many AAA titles. At some point, a list of indices becomes
	// more compact in practice, so if thousands of lights are needed, that's probably the way to go. Using a fixed bitmask has the advantage of fixed
	// size storage, simple addressing, and one indirection less in the inner loop.
	// "
	uint lightMask = TEXTURE_FETCH_3D(LightClustersMap3D, int4(worldSpacePosition * PassData.LightClustersScale + PassData.LightClustersBias, 0)).x;

	// Point and spot lights using clustered shading
	while (lightMask)
	{
		// Extract a light from the mask and disable that bit
		uint lightIndex = firstbitlow(lightMask);
		lightMask &= ~(1 << lightIndex);
		
		// Check if the fragment is inside the bounding volume of the light
		float4 lightPositionRadius = TEXTURE_BUFFER_FETCH(LightTextureBuffer, lightIndex * 4u);
		float3 direction = lightPositionRadius.xyz - worldSpacePosition;
		float distance = length(direction);
		if (distance < lightPositionRadius.w)
		{
			float4 lightColorType = TEXTURE_BUFFER_FETCH(LightTextureBuffer, lightIndex * 4u + 1u);
			float lightIntensity = 1.0f;

			// Normalize the direction
			direction /= distance;

			// Spot-light attenuation
			if (2.0f == lightColorType.w)
			{
				float4 innerOuterNearClip = TEXTURE_BUFFER_FETCH(LightTextureBuffer, lightIndex * 4u + 2u);
				if (distance < innerOuterNearClip.z)
				{
					// Early escape: Not influenced by the light
					continue;
				}
				float3 spotlightDirection = TEXTURE_BUFFER_FETCH(LightTextureBuffer, lightIndex * 4u + 3u).xyz;
				float spotlightAngle = SATURATE(dot(spotlightDirection, -direction));
				float spotlightFalloff = SATURATE((spotlightAngle - innerOuterNearClip.x) / (innerOuterNearClip.y - innerOuterNearClip.x));
				lightIntensity *= (1.0f - spotlightFalloff);
			}

			// Attenuation by using inverse-square falloff for higher quality falloff
			// -> Physically accurate inverse-square falloff as described in "Real Shading in Unreal Engine 4" by Brian Karis, Epic Games - "Lighting Model" on page 12 - http://blog.selfshadow.com/publications/s2013-shading-course/karis/s2013_pbs_epic_notes_v2.pdf
			float distanceLightRadius = distance / lightPositionRadius.w;
			float t1 = SATURATE(1.0f - distanceLightRadius * distanceLightRadius * distanceLightRadius * distanceLightRadius);
			lightIntensity *= t1 / (distance * distance + 1.0f);

			// Calculate lighting
			if (lightIntensity > 0.0f)
			{
				float3 worldSpaceNormal = MultiplyQuaternionVector(PassData.ViewSpaceToWorldSpaceQuaternion, viewSpaceNormal);
				if (dot(worldSpaceNormal, direction) > 0.0f)
				{
					float3 worldSpaceIncident = MultiplyQuaternionVector(PassData.ViewSpaceToWorldSpaceQuaternion, viewSpaceIncident);
					color += CalculateLighting(diffuse, roughness, metallic, worldSpaceNormal, worldSpaceIncident, direction, lightColorType.rgb * lightIntensity);
				}
			}
		}
	}

	// Apply screen space ambient occlusion
	color *= float3(screenSpaceAmbientOcclusion, screenSpaceAmbientOcclusion, screenSpaceAmbientOcclusion);

	// Emissive term
	color += emissive;

	// Done
	return color;
}


//[-------------------------------------------------------]
//[ Main                                                  ]
//[-------------------------------------------------------]
MAIN_BEGIN
	// Get the normalized view ray
	float3 viewRay = normalize(MAIN_INPUT(ViewRayVS));

	// Gather screen space ambient occlusion value
	float screenSpaceAmbientOcclusion = SAMPLE_2D_LOD(ScreenSpaceAmbientOcclusionMap, SamplerPoint, float4(MAIN_INPUT(TexCoordVS), 0.0f, 0.0f)).r;

	// Calculate color by GBuffer
	@property(NumberOfMultisamples)
		// Custom MSAA resolve
		int2 textureCoordinate = int2(MAIN_INPUT(TexCoordVS) * PassData.ViewportSize);
		float3 color = float3(0.0f, 0.0f, 0.0f);
		int numberOfValues = 0;
		@foreach(NumberOfMultisamples, i, 0)
		{
			// Read depth map value and check whether or not a depth value was written (depth = 1 = depth clear value)
			float depth = SAMPLE_DEPTH_2D_MS(DepthMap, textureCoordinate, @i);
			if (1.0f != depth)
			{
				// Read GBuffer data
				float4 gbuffer0Value = SAMPLE_2D_MS(GBufferMap0, textureCoordinate, @i);
				float4 gbuffer1Value = SAMPLE_2D_MS(GBufferMap1, textureCoordinate, @i);
				float4 gbuffer2Value = SAMPLE_2D_MS(GBufferMap2, textureCoordinate, @i);

				// Calculate color by GBuffer
				color += CalculateColorByGBuffer(viewRay, MAIN_INPUT(TexCoordVS), gbuffer0Value, gbuffer1Value, gbuffer2Value, depth, screenSpaceAmbientOcclusion);
				++numberOfValues;
			}
		}
		@end
		if (numberOfValues > 0)
		{
			color /= numberOfValues;
		}
		else
		{
			// Visible aliasing comes up. Since there's still also shader aliasing etc. one might want to use FXAA or so on top of everything.
			discard;
		}
	@end
	@property(!NumberOfMultisamples)
		float4 textureCoordinate = float4(MAIN_INPUT(TexCoordVS), 0.0f, 0.0f);

		// Read depth map value and check whether or not a depth value was written (depth = 1 = depth clear value)
		float depth = SAMPLE_DEPTH_2D_LOD(DepthMap, SamplerPoint, textureCoordinate);
		if (1.0f == depth)
		{
			discard;
		}

		// Read GBuffer data
		float4 gbuffer0Value = SAMPLE_2D_LOD(GBufferMap0, SamplerPoint, textureCoordinate);
		float4 gbuffer1Value = SAMPLE_2D_LOD(GBufferMap1, SamplerPoint, textureCoordinate);
		float4 gbuffer2Value = SAMPLE_2D_LOD(GBufferMap2, SamplerPoint, textureCoordinate);

		// Calculate color by GBuffer
		float3 color = CalculateColorByGBuffer(viewRay, MAIN_INPUT(TexCoordVS), gbuffer0Value, gbuffer1Value, gbuffer2Value, depth, screenSpaceAmbientOcclusion);
	@end

	// Done
	MAIN_OUTPUT_COLOR(0) = float4(color, 1.0f);
MAIN_END
